---
title: "Data analysis"
author: matkob
date: 12.11.2020
output: html_notebook
---

```{r message=FALSE}
# uncomment for generating html file
# setwd('..')
library(dplyr)
library(knitr)
library(rmarkdown)

df <- read.csv('data/winemag-data_first150k.csv', header = TRUE)
head(df)
```
<h2>Price vs Points</h2>
```{r }
plot(x=df$price, xlab='price', y=df$points, ylab='points')
```
<h2>Price Outliers</h2>
```{r}
boxplot(df$price, horizontal=TRUE)
remove_outliers <- function(df, col) {
  df[!df[[col]] %in% boxplot.stats(df[[col]])$out, ]
}
remove_missing <- function(df) {
    df[complete.cases(df), ]
}
boxplot(remove_outliers(df, 'price')$price, horizontal=TRUE)
```
<h2>Price vs Points 2</h2>
```{r}
price_qnt <- remove_outliers(df, 'price')
plot(x=price_qnt$price, xlab='price', y=price_qnt$points, ylab='points')
```
<h2>Points</h2>
```{r}
hist(df$points, breaks=c(0, 25, 50, 75, 100), xlab='points', main='Points distribution')
plot(ecdf(df$points), main='Cumulative distribution of points')
hist(
    df$points,
    breaks=c(80,90,100),
    col=c('#74b9ff', '#e17055'),
    xlab='points',
    main='Points distribution'
)
```
<h2>Glove Values</h2>
```{r}
source("utils/loader_glove.r")
# loading glove dataset
vectors <- load_glove(oversampling = FALSE)
```
```{r}
hist(
  apply(vectors[[1]], 2, sd),
  breaks = 100,
  col=c('#74b9ff', '#e17055', '#fdcb6e'),
  cex.lab=2,
  xlab='std dev',
  main='Std dev distribution'
)
```
<h2>Words occurrence</h2>
```{r}
library(SnowballC)
library(tidytext)

data('stop_words')
descr <- df$description
descr <- gsub('@\\w+', '', descr)
# links
descr <- gsub('https?://.+', '', descr)
# digits
descr <- gsub('\\d+\\w*\\d*', '', descr)
descr <- gsub('#\\w+', '', descr)
descr <- gsub('[^\x01-\x7F]', '', descr)
# punctuation
descr <- gsub('[[:punct:]]', ' ', descr)
# new lines
descr <- gsub('\n', ' ', descr)
descr <- gsub('^\\s+', '', descr)
descr <- gsub('\\s+$', '', descr)
descr <- gsub('[ |\t]+', ' ', descr)
df['text'] <- descr
# sentences to words
text_data <- mutate(df, text = as.character(text)) %>%
    select(text) %>%
    unnest_tokens("word", text)
# removing stopwords
text_data <- data.frame(text_data$word[!(text_data$word %in% stop_words$word)])
names(text_data) <- 'word'
# counting occurrence
common <- text_data %>% count(word) %>% arrange(desc(n))
head(common, 10)
```


```{r}
    library(wordcloud)
    library(RColorBrewer)
    library(text2vec)
    wine <- read_csv('data/winemag-data_first150k.csv')
    wine <- subset(wine, select = c(X1, points, price, description))
    wine$sentiment <- ifelse(wine$points>90, 1, 0)

    setDT(wine)
    setkey(wine, X1)

    all_ids <- wine$X1
    sample_size <- floor(0.8 * nrow(wine))
    train_ids <- sample(all_ids, sample_size)
    test_ids <- setdiff(all_ids, train_ids)
    train <- wine[J(train_ids)]
    test <- wine[J(test_ids)]

    # define preprocessing function and tokenization function
    prep_fun <- tolower

    stem_tokenizer <- function(x) {
    lapply(word_tokenizer(x), SnowballC::wordStem, language="en")
    }


    it_train <- itoken(train$description,
                     preprocessor = prep_fun,
                     tokenizer = stem_tokenizer,
                     ids = train$X1,
                     progressbar = FALSE)

    vocab <- create_vocabulary(it_train, stopwords = stopwords("en"))
    pruned_vocab <- prune_vocabulary(vocab,
                                   term_count_min = 50,
                                   doc_proportion_max = 0.5)

    vectorizer <- vocab_vectorizer(pruned_vocab)
    # create document term matrix

    wordcloud(words = pruned_vocab$term, freq = pruned_vocab$doc_count, min.freq = 1,
              max.words=200, random.order=FALSE, rot.per=0.35,
            colors=brewer.pal(8, "Dark2"))


```